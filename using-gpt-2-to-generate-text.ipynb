{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPT-2 to generate Text\n",
    "This Notebook shows how to use the recently published [GPT-2](https://github.com/openai/gpt-2) Model to generate new text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Content\n",
    "1. [Introduction](#1)\n",
    "    1. [Basic Import](#11)\n",
    "    2. [Download the model](#12)\n",
    "    3. [Import the model](#13)\n",
    "2. [Configuration](#2)\n",
    "    1. [Path declaration](#21)\n",
    "    2. [Load model and bpe](#22)\n",
    "    3. [Define Input and get the Output](#23)\n",
    "3. [Conclusion](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1.0 Introduction\n",
    "This Notebook shows the usage of GPT-2 using the available 117M Model, to generate new text. The goal is to be able to choose the text the model should finish, to get a quick glance at how 'good' AI already is regarding text comprehention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"11\"></a>\n",
    "### 1.1 Basic Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model.ckpt.data-00000-of-00001', 'encoder.json', 'model.ckpt.meta', 'model.ckpt.index', 'vocab.bpe', 'hparams.json', 'checkpoint']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"12\"></a>\n",
    "### 1.2 Download the model\n",
    "We need to download the model using pip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-gpt-2\r\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/5d/c540b090c3555a5c9c653c19ac1b633c63249d2c2bed515bddf4b2eca43a/keras-gpt-2-0.7.0.tar.gz\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from keras-gpt-2) (1.16.2)\r\n",
      "Requirement already satisfied: Keras in /opt/conda/lib/python3.6/site-packages (from keras-gpt-2) (2.2.4)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from keras-gpt-2) (2019.3.12)\r\n",
      "Collecting keras-embed-sim==0.3.0 (from keras-gpt-2)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/16/b05954f9578ded225fd1bd56154ade949782c03b668a1fc424d5050e868a/keras-embed-sim-0.3.0.tar.gz\r\n",
      "Collecting keras-pos-embd==0.8.0 (from keras-gpt-2)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/09/7b/fbb75fd0ab68f9728c1bff197a2cbc5a9a3874af27d44023f92fa32cb12c/keras-pos-embd-0.8.0.tar.gz\r\n",
      "Collecting keras-layer-normalization==0.11.0 (from keras-gpt-2)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/b0/c786d5a5e79d985281a06da0a1f3f559cf425921464e6b07b9f1cb093a5a/keras-layer-normalization-0.11.0.tar.gz\r\n",
      "Collecting keras-transformer==0.19.0 (from keras-gpt-2)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/4d/61/4ffb5d3f8fc50f1dd33132af5869f3779052f3e18b0829cc95d4ad2dce7d/keras-transformer-0.19.0.tar.gz\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from Keras->keras-gpt-2) (3.12)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-gpt-2) (1.12.0)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-gpt-2) (1.0.9)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from Keras->keras-gpt-2) (2.9.0)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-gpt-2) (1.0.7)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from Keras->keras-gpt-2) (1.1.0)\r\n",
      "Collecting keras-multi-head==0.16.0 (from keras-transformer==0.19.0->keras-gpt-2)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/c9/7811e06a523c743d1a7449e8647d2ef1c7713248e27ea6f6b23772d38881/keras-multi-head-0.16.0.tar.gz\r\n",
      "Collecting keras-position-wise-feed-forward==0.4.0 (from keras-transformer==0.19.0->keras-gpt-2)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/91/21/4eefba0b6ea01de9c6e469970a39dbdbce14e5183a20274d9a181f55eaa8/keras-position-wise-feed-forward-0.4.0.tar.gz\r\n",
      "Collecting keras-self-attention==0.35.0 (from keras-multi-head==0.16.0->keras-transformer==0.19.0->keras-gpt-2)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/b7/93e762cd4db6cd444ff96f64d1f6ba4410358337aeafaf47972b7687f96a/keras-self-attention-0.35.0.tar.gz\r\n",
      "Building wheels for collected packages: keras-gpt-2, keras-embed-sim, keras-pos-embd, keras-layer-normalization, keras-transformer, keras-multi-head, keras-position-wise-feed-forward, keras-self-attention\r\n",
      "  Building wheel for keras-gpt-2 (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/28/73/cb/62fcbb7be100b0b06bfb3952fe08d22829775019e2064f499d\r\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/bf/f2/c6/0610efe9730c708b24ec29c25cebd38eb485acbc2eee7b5634\r\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/b2/28/d8/36dbba40b3321d93f0ec281d4d8bdfea84e020781397378c23\r\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/86/dc/2e/3ac54a6b948bff68cb999d210c6ebf9e22df7a4a24cf114436\r\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/f8/57/33/681eca61700b2024efcc2a551960d70c040a2f5d7724d63265\r\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/a0/60/16/dd1924b189261e891ef43670665299a449c33bc9b2a5ae3c8d\r\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/40/a1/13/3c913efde102d56ac584f61004a9fec6f8859b6feec6aa7aa7\r\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/e3/e9/c8/5d54f092f7e6704aede1b520849cd8350107295bd5db51e2fe\r\n",
      "Successfully built keras-gpt-2 keras-embed-sim keras-pos-embd keras-layer-normalization keras-transformer keras-multi-head keras-position-wise-feed-forward keras-self-attention\r\n",
      "\u001b[31mkeras-transformer 0.19.0 has requirement keras-embed-sim==0.2.0, but you'll have keras-embed-sim 0.3.0 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: keras-embed-sim, keras-pos-embd, keras-layer-normalization, keras-self-attention, keras-multi-head, keras-position-wise-feed-forward, keras-transformer, keras-gpt-2\r\n",
      "Successfully installed keras-embed-sim-0.3.0 keras-gpt-2-0.7.0 keras-layer-normalization-0.11.0 keras-multi-head-0.16.0 keras-pos-embd-0.8.0 keras-position-wise-feed-forward-0.4.0 keras-self-attention-0.35.0 keras-transformer-0.19.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-gpt-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"13\"></a>\n",
    "### 1.3 Import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras_gpt_2 import load_trained_model_from_checkpoint, get_bpe_from_files, generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"21\"></a>\n",
    "### 2.1 Path declaration\n",
    "The path declaration was done for the Kaggle file system. If you download the notebook and the model, you need to determine the correct path for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"../input\"\n",
    "config_path = os.path.join(model_folder, 'hparams.json')\n",
    "checkpoint_path = os.path.join(model_folder, 'model.ckpt')\n",
    "encoder_path = os.path.join(model_folder, 'encoder.json')\n",
    "vocab_path = os.path.join(model_folder, 'vocab.bpe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"22\"></a>\n",
    "### 2.2 Load model and bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model from checkpoint...\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "print('Load model from checkpoint...')\n",
    "model = load_trained_model_from_checkpoint(config_path, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load BPE from files...\n"
     ]
    }
   ],
   "source": [
    "print('Load BPE from files...')\n",
    "bpe = get_bpe_from_files(encoder_path, vocab_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"23\"></a>\n",
    "### 2.3 Define Input and get the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate text...\n"
     ]
    }
   ],
   "source": [
    "myInput = ['The meaning of life is']\n",
    "print('Generate text...')\n",
    "output = generate(model, bpe, myInput, length=20, top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The meaning of life is not to be taken for granted. It is not to be taken for a given person. Life does']\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. Conclusion\n",
    "After trying different examples of text, it is quite clear that the model isn't even close to being perfect. However, with most examples, the model seems to understand what the topic is and how to finish most of the sentences with some meaning. The model which was not published due to ethically reasons, might be already way better than this one. The progress over the last decades are very impressive and it seems only a matter of time, when the first AI will write the first bestseller novel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
